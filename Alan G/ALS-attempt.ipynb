{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58398d4-48e4-454e-95b1-e3c2b62bbbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/venv/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/venv/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/venv/lib/python3.10/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "global_train_df = pd.read_csv(\"../MATHM0029_2024_TB-1/global_train_df.csv\")\n",
    "global_test_df = pd.read_csv(\"../MATHM0029_2024_TB-1/global_test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b705c22-ac5c-4b5f-a892-25e29eaad10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/venv/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/venv/lib/python3.10/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/venv/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   User ID  Item ID  Rating  timestamp  Age  Gender  Occupation zip code  \\\n",
       " 0      864     1044       3  888891049   27       1          14    63021   \n",
       " 1      864      159       4  888891049   27       1          14    63021   \n",
       " 2      864     1303       2  888890997   27       1          14    63021   \n",
       " 3      864      184       4  888890775   27       1          14    63021   \n",
       " 4      864     1531       3  888890690   27       1          14    63021   \n",
       " \n",
       "                                          Movie Title  Release Date  ...  \\\n",
       " 0                                  Paper, The (1994)           NaN  ...   \n",
       " 1                              Basic Instinct (1992)           NaN  ...   \n",
       " 2                                Getaway, The (1994)           NaN  ...   \n",
       " 3                            Army of Darkness (1993)           NaN  ...   \n",
       " 4  Far From Home: The Adventures of Yellow Dog (1...           NaN  ...   \n",
       " \n",
       "    Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  User_Age  \\\n",
       " 0      0.0      0.0      0.0     0.0       0.0  0.0      0.0        27   \n",
       " 1      0.0      1.0      0.0     0.0       1.0  0.0      0.0        27   \n",
       " 2      0.0      0.0      0.0     0.0       0.0  0.0      0.0        27   \n",
       " 3      0.0      0.0      0.0     1.0       0.0  0.0      0.0        27   \n",
       " 4      0.0      0.0      0.0     0.0       0.0  0.0      0.0        27   \n",
       " \n",
       "    User_Gender  User_Occupation  \n",
       " 0            1               14  \n",
       " 1            1               14  \n",
       " 2            1               14  \n",
       " 3            1               14  \n",
       " 4            1               14  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       "    User ID  Item ID  Rating  timestamp  Age  Gender  Occupation zip code  \\\n",
       " 0      729      300       4  893286638   19       1          18    56567   \n",
       " 1      683      248       4  893286603   42       1          10    23509   \n",
       " 2      683      588       4  893286584   42       1          10    23509   \n",
       " 3      683      187       5  893286501   42       1          10    23509   \n",
       " 4      683     1483       3  893286346   42       1          10    23509   \n",
       " \n",
       "                         Movie Title Release Date  ... Musical Mystery  \\\n",
       " 0              Air Force One (1997)  01-Jan-1997  ...       0     0.0   \n",
       " 1        Grosse Pointe Blank (1997)  11-Apr-1997  ...       0     0.0   \n",
       " 2       Beauty and the Beast (1991)  01-Jan-1991  ...       1     0.0   \n",
       " 3    Godfather: Part II, The (1974)  01-Jan-1974  ...       0     0.0   \n",
       " 4  Man in the Iron Mask, The (1998)  17-Mar-1998  ...       0     0.0   \n",
       " \n",
       "    Romance Sci-Fi Thriller  War Western User_Age  User_Gender User_Occupation  \n",
       " 0        0      0      1.0    0       0      NaN          NaN             NaN  \n",
       " 1        0      0      0.0    0       0      NaN          NaN             NaN  \n",
       " 2        0      0      0.0    0       0      NaN          NaN             NaN  \n",
       " 3        0      0      0.0    0       0      NaN          NaN             NaN  \n",
       " 4        1      0      0.0    0       0      NaN          NaN             NaN  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       "          Release Date  URL  Unknown  Action  Adeventure  Animation  Childrens  \\\n",
       " Item ID                                                                         \n",
       " 1                 NaN  NaN      0.0     0.0         0.0        1.0        1.0   \n",
       " 2                 NaN  NaN      0.0     1.0         1.0        0.0        0.0   \n",
       " 3                 NaN  NaN      0.0     0.0         0.0        0.0        0.0   \n",
       " 4                 NaN  NaN      0.0     1.0         0.0        0.0        0.0   \n",
       " 5                 NaN  NaN      0.0     0.0         0.0        0.0        0.0   \n",
       " \n",
       "          Comedy  Crime  Documentary  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       " Item ID                              ...                                        \n",
       " 1           1.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
       " 2           0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
       " 3           0.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
       " 4           1.0    0.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
       " 5           0.0    1.0          0.0  ...      0.0        0.0     0.0      0.0   \n",
       " \n",
       "          Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       " Item ID                                                    \n",
       " 1            0.0      0.0     0.0       0.0  0.0      0.0  \n",
       " 2            0.0      0.0     0.0       1.0  0.0      0.0  \n",
       " 3            0.0      0.0     0.0       1.0  0.0      0.0  \n",
       " 4            0.0      0.0     0.0       0.0  0.0      0.0  \n",
       " 5            0.0      0.0     0.0       1.0  0.0      0.0  \n",
       " \n",
       " [5 rows x 21 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode user and item metadata\n",
    "user_metadata_columns = ['Age', 'Gender', 'Occupation']\n",
    "item_metadata_columns = list(global_train_df.columns[9:])  # All columns from 'unknown' to 'Western'\n",
    "\n",
    "# Label encode categorical columns like Gender and Occupation\n",
    "label_encoders = {col: LabelEncoder() for col in user_metadata_columns if global_train_df[col].dtype == 'object'}\n",
    "\n",
    "for col, encoder in label_encoders.items():\n",
    "    global_train_df[col] = encoder.fit_transform(global_train_df[col])\n",
    "    global_test_df[col] = encoder.transform(global_test_df[col])\n",
    "\n",
    "# Aggregate genre metadata for items\n",
    "# Ensure all genre columns are numeric and handle non-numeric data\n",
    "for col in item_metadata_columns:\n",
    "    global_train_df[col] = pd.to_numeric(global_train_df[col], errors='coerce')\n",
    "\n",
    "# Re-aggregate item genres after converting to numeric\n",
    "item_genres = global_train_df.groupby('Item ID')[item_metadata_columns].mean()\n",
    "\n",
    "# Verify the aggregated data to ensure no issues\n",
    "item_genres.head()\n",
    "\n",
    "# Merge user metadata with ratings in train/test sets\n",
    "# Rename user metadata columns to avoid overlap\n",
    "user_metadata = user_metadata.rename(columns={\n",
    "    'Age': 'User_Age',\n",
    "    'Gender': 'User_Gender',\n",
    "    'Occupation': 'User_Occupation'\n",
    "})\n",
    "\n",
    "global_train_df = global_train_df.set_index('User ID').join(user_metadata).reset_index()\n",
    "global_test_df = global_test_df.set_index('User ID').join(user_metadata).reset_index()\n",
    "\n",
    "# Verify the preprocessed data structure\n",
    "global_train_df.head(), global_test_df.head(), item_genres.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6b0a4e9-5c42-46c2-b499-1fac3d3e5a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0462375221696674"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"MatrixFactorization\").getOrCreate()\n",
    "\n",
    "# Convert training and test datasets to Spark DataFrames\n",
    "global_train_sdf = spark.createDataFrame(global_train_df[['User ID', 'Item ID', 'Rating']])\n",
    "global_test_sdf = spark.createDataFrame(global_test_df[['User ID', 'Item ID', 'Rating']])\n",
    "\n",
    "# Define ALS model\n",
    "als = ALS(\n",
    "    userCol=\"User ID\",\n",
    "    itemCol=\"Item ID\",\n",
    "    ratingCol=\"Rating\",\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=10,\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Train the ALS model\n",
    "als_model = als.fit(global_train_sdf)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "predictions = als_model.transform(global_test_sdf)\n",
    "\n",
    "# Calculate RMSE for evaluation\n",
    "evaluator_rmse = predictions.select((col(\"Rating\") - col(\"prediction\")) ** 2).agg({\"POWER((Rating - prediction), 2)\": \"mean\"})\n",
    "rmse = evaluator_rmse.first()[0] ** 0.5\n",
    "\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9760f0c-cbf0-4b83-aea2-06b7ad4ae444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Combine ALS embeddings and metadata\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m user_combined_features \u001b[38;5;241m=\u001b[39m \u001b[43muser_embeddings\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(pd\u001b[38;5;241m.\u001b[39mDataFrame(user_embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()))\n\u001b[1;32m      6\u001b[0m item_combined_features \u001b[38;5;241m=\u001b[39m item_embeddings\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(pd\u001b[38;5;241m.\u001b[39mDataFrame(item_embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between user and item combined features\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Combine ALS embeddings and metadata\n",
    "user_combined_features = user_embeddings.drop('features', axis=1).join(pd.DataFrame(user_embeddings['features'].to_list()))\n",
    "item_combined_features = item_embeddings.drop('features', axis=1).join(pd.DataFrame(item_embeddings['features'].to_list()))\n",
    "\n",
    "# Compute cosine similarity between user and item combined features\n",
    "user_vectors = np.array(user_combined_features.iloc[:, 1:])\n",
    "item_vectors = np.array(item_combined_features.iloc[:, 1:])\n",
    "similarity_matrix = cosine_similarity(user_vectors, item_vectors)\n",
    "\n",
    "# Generate top-k recommendations for each user\n",
    "top_k_recommendations = np.argsort(-similarity_matrix, axis=1)[:, :10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbbbd5-b684-4d03-9709-4aa0f7321df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
