{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering using a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by using code from https://python.plainenglish.io/collaborative-filtering-recommendation-system-using-tensorflow-with-neural-net-7f8dba4521da and see if can get something similar working for our data and then progress from there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our Testing and Training split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll focus on just the global split for now and do comparison later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train_df = pd.read_csv('../Katherine W/global_train_df.csv')\n",
    "global_test_df = pd.read_csv('../Katherine W/global_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Item ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>zip code</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>864</td>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>888891049</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>63021</td>\n",
       "      <td>Paper, The (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864</td>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>888891049</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>63021</td>\n",
       "      <td>Basic Instinct (1992)</td>\n",
       "      <td>01-Jan-1992</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864</td>\n",
       "      <td>1303</td>\n",
       "      <td>2</td>\n",
       "      <td>888890997</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>63021</td>\n",
       "      <td>Getaway, The (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>888890775</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>63021</td>\n",
       "      <td>Army of Darkness (1993)</td>\n",
       "      <td>01-Jan-1993</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864</td>\n",
       "      <td>1531</td>\n",
       "      <td>3</td>\n",
       "      <td>888890690</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>63021</td>\n",
       "      <td>Far From Home: The Adventures of Yellow Dog (1...</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Item ID  Rating  timestamp  Age Gender  Occupation zip code  \\\n",
       "0      864     1044       3  888891049   27      M  programmer    63021   \n",
       "1      864      159       4  888891049   27      M  programmer    63021   \n",
       "2      864     1303       2  888890997   27      M  programmer    63021   \n",
       "3      864      184       4  888890775   27      M  programmer    63021   \n",
       "4      864     1531       3  888890690   27      M  programmer    63021   \n",
       "\n",
       "                                         Movie Title Release Date  ...  \\\n",
       "0                                  Paper, The (1994)  01-Jan-1994  ...   \n",
       "1                              Basic Instinct (1992)  01-Jan-1992  ...   \n",
       "2                                Getaway, The (1994)  01-Jan-1994  ...   \n",
       "3                            Army of Darkness (1993)  01-Jan-1993  ...   \n",
       "4  Far From Home: The Adventures of Yellow Dog (1...  01-Jan-1995  ...   \n",
       "\n",
       "  Fantasy Film-Noir  Horror Musical Mystery  Romance Sci-Fi Thriller  War  \\\n",
       "0       0       0.0       0       0     0.0        0      0      0.0    0   \n",
       "1       0       0.0       0       0     1.0        0      0      1.0    0   \n",
       "2       0       0.0       0       0     0.0        0      0      0.0    0   \n",
       "3       0       0.0       1       0     0.0        0      1      0.0    0   \n",
       "4       0       0.0       0       0     0.0        0      0      0.0    0   \n",
       "\n",
       "  Western  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use only the user id and item id as features for the movie rating for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">47,200</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">84,150</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m47,200\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m84,150\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,407</span> (564.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,407\u001b[0m (564.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,407</span> (564.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,407\u001b[0m (564.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\44747\\anaconda3\\envs\\GroupAssignment2\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['user_input', 'item_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.5908 - val_loss: 1.5800\n",
      "Epoch 2/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9137 - val_loss: 1.4175\n",
      "Epoch 3/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8629 - val_loss: 1.2726\n",
      "Epoch 4/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8587 - val_loss: 1.2688\n",
      "Epoch 5/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8448 - val_loss: 1.2291\n",
      "Epoch 6/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8446 - val_loss: 1.1619\n",
      "Epoch 7/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8296 - val_loss: 1.1152\n",
      "Epoch 8/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8165 - val_loss: 1.1238\n",
      "Epoch 9/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8129 - val_loss: 1.1113\n",
      "Epoch 10/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7838 - val_loss: 1.1207\n",
      "Epoch 11/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7791 - val_loss: 1.1091\n",
      "Epoch 12/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7582 - val_loss: 1.0727\n",
      "Epoch 13/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7466 - val_loss: 1.1176\n",
      "Epoch 14/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7302 - val_loss: 1.1402\n",
      "Epoch 15/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7173 - val_loss: 1.1112\n",
      "Epoch 16/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6878 - val_loss: 1.1096\n",
      "Epoch 17/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6825 - val_loss: 1.0926\n",
      "Epoch 18/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6557 - val_loss: 1.1065\n",
      "Epoch 19/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6336 - val_loss: 1.0590\n",
      "Epoch 20/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6267 - val_loss: 1.1077\n",
      "Epoch 21/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6024 - val_loss: 1.1413\n",
      "Epoch 22/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5714 - val_loss: 1.1123\n",
      "Epoch 23/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5611 - val_loss: 1.1383\n",
      "Epoch 24/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5631 - val_loss: 1.1722\n",
      "Epoch 25/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5128 - val_loss: 1.1600\n",
      "Epoch 26/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4998 - val_loss: 1.1259\n",
      "Epoch 27/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4806 - val_loss: 1.1656\n",
      "Epoch 28/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4744 - val_loss: 1.1446\n",
      "Epoch 29/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4496 - val_loss: 1.1309\n",
      "Epoch 30/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4363 - val_loss: 1.1834\n",
      "Epoch 31/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4053 - val_loss: 1.1762\n",
      "Epoch 32/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3993 - val_loss: 1.1647\n",
      "Epoch 33/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3910 - val_loss: 1.1694\n",
      "Epoch 34/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3782 - val_loss: 1.1777\n",
      "Epoch 35/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3663 - val_loss: 1.1921\n",
      "Epoch 36/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3492 - val_loss: 1.2306\n",
      "Epoch 37/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3388 - val_loss: 1.2175\n",
      "Epoch 38/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3233 - val_loss: 1.2371\n",
      "Epoch 39/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3146 - val_loss: 1.2120\n",
      "Epoch 40/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3034 - val_loss: 1.2171\n",
      "Epoch 41/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2822 - val_loss: 1.2570\n",
      "Epoch 42/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2769 - val_loss: 1.2660\n",
      "Epoch 43/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2671 - val_loss: 1.2681\n",
      "Epoch 44/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2640 - val_loss: 1.2565\n",
      "Epoch 45/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2519 - val_loss: 1.3024\n",
      "Epoch 46/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2392 - val_loss: 1.2870\n",
      "Epoch 47/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2311 - val_loss: 1.3116\n",
      "Epoch 48/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2190 - val_loss: 1.3203\n",
      "Epoch 49/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2178 - val_loss: 1.3375\n",
      "Epoch 50/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2121 - val_loss: 1.3449\n",
      "Epoch 51/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1956 - val_loss: 1.3727\n",
      "Epoch 52/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.1997 - val_loss: 1.3689\n",
      "Epoch 53/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.1865 - val_loss: 1.3977\n",
      "Epoch 54/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1857 - val_loss: 1.3792\n",
      "Epoch 55/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1715 - val_loss: 1.4033\n",
      "Epoch 56/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1708 - val_loss: 1.3944\n",
      "Epoch 57/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1637 - val_loss: 1.4470\n",
      "Epoch 58/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.1605 - val_loss: 1.4228\n",
      "Epoch 59/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1534 - val_loss: 1.4469\n",
      "Epoch 60/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1478 - val_loss: 1.4274\n",
      "Epoch 61/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1406 - val_loss: 1.4580\n",
      "Epoch 62/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1361 - val_loss: 1.4618\n",
      "Epoch 63/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1349 - val_loss: 1.4835\n",
      "Epoch 64/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1297 - val_loss: 1.4810\n",
      "Epoch 65/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1256 - val_loss: 1.4763\n",
      "Epoch 66/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1216 - val_loss: 1.4942\n",
      "Epoch 67/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1192 - val_loss: 1.5147\n",
      "Epoch 68/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1137 - val_loss: 1.4942\n",
      "Epoch 69/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1124 - val_loss: 1.5044\n",
      "Epoch 70/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1109 - val_loss: 1.5150\n",
      "Epoch 71/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.1052 - val_loss: 1.5094\n",
      "Epoch 72/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1023 - val_loss: 1.4970\n",
      "Epoch 73/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0977 - val_loss: 1.5216\n",
      "Epoch 74/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0950 - val_loss: 1.5449\n",
      "Epoch 75/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0956 - val_loss: 1.5477\n",
      "Epoch 76/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0949 - val_loss: 1.5246\n",
      "Epoch 77/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0883 - val_loss: 1.5184\n",
      "Epoch 78/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0862 - val_loss: 1.5366\n",
      "Epoch 79/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0848 - val_loss: 1.5105\n",
      "Epoch 80/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0804 - val_loss: 1.5394\n",
      "Epoch 81/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0800 - val_loss: 1.5559\n",
      "Epoch 82/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.0775 - val_loss: 1.5076\n",
      "Epoch 83/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0748 - val_loss: 1.5222\n",
      "Epoch 84/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0734 - val_loss: 1.5475\n",
      "Epoch 85/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0737 - val_loss: 1.5650\n",
      "Epoch 86/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.0692 - val_loss: 1.5428\n",
      "Epoch 87/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0675 - val_loss: 1.5539\n",
      "Epoch 88/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0657 - val_loss: 1.5607\n",
      "Epoch 89/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0661 - val_loss: 1.5683\n",
      "Epoch 90/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0651 - val_loss: 1.5597\n",
      "Epoch 91/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0639 - val_loss: 1.5608\n",
      "Epoch 92/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0628 - val_loss: 1.5787\n",
      "Epoch 93/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0604 - val_loss: 1.5376\n",
      "Epoch 94/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0576 - val_loss: 1.5628\n",
      "Epoch 95/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0588 - val_loss: 1.5722\n",
      "Epoch 96/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0553 - val_loss: 1.5832\n",
      "Epoch 97/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0560 - val_loss: 1.5538\n",
      "Epoch 98/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0558 - val_loss: 1.5704\n",
      "Epoch 99/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0531 - val_loss: 1.5561\n",
      "Epoch 100/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0522 - val_loss: 1.5539\n"
     ]
    }
   ],
   "source": [
    "# Define the number of unique users and items in the dataset\n",
    "num_users = global_train_df['User ID'].max()\n",
    "num_items = global_train_df['Item ID'].max()\n",
    "\n",
    "# Define the embedding size\n",
    "embedding_size = 50\n",
    "\n",
    "# Define the input layers\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "item_input = Input(shape=(1,), name='item_input')\n",
    "\n",
    "# Define the embedding layers\n",
    "user_embedding = Embedding(input_dim=num_users + 1, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "item_embedding = Embedding(input_dim=num_items + 1, output_dim=embedding_size, name='item_embedding')(item_input)\n",
    "\n",
    "# Flatten the embedding layers\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "# Concatenate the user and item vectors\n",
    "concat = Concatenate()([user_vecs, item_vecs])\n",
    "\n",
    "# Add a dense layer\n",
    "dense = Dense(128, activation='relu')(concat)\n",
    "output = Dense(1)(dense)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Prepare the training data\n",
    "X_train = [global_train_df['User ID'].values, global_train_df['Item ID'].values]\n",
    "y_train = global_train_df['Rating'].values\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "     Item ID  Predicted Rating\n",
      "10       423          5.825243\n",
      "355     1512          5.735898\n",
      "105      867          5.662412\n",
      "136     1012          5.612129\n",
      "113      875          5.565384\n",
      "319     1473          5.499070\n",
      "106      868          5.471953\n",
      "73       594          5.448125\n",
      "433     1643          5.438506\n",
      "188     1073          5.436777\n"
     ]
    }
   ],
   "source": [
    "# Define the user_id and unrated_items\n",
    "user_id = 1  # Example user_id, you can change it based on your dataset\n",
    "rated_items = global_train_df[global_train_df['User ID'] == user_id]['Item ID'].values\n",
    "all_items = global_train_df['Item ID'].unique()\n",
    "unrated_items = np.setdiff1d(all_items, rated_items)\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "user_input_pred = np.array([user_id] * len(unrated_items))\n",
    "item_input_pred = unrated_items\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict([user_input_pred, item_input_pred])\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame({'Item ID': unrated_items, 'Predicted Rating': predictions.flatten()})\n",
    "\n",
    "# Sort the predictions in descending order\n",
    "predictions_df = predictions_df.sort_values(by='Predicted Rating', ascending=False)\n",
    "\n",
    "# Get the top 10 recommendations\n",
    "top_10_recommendations = predictions_df.head(10)\n",
    "\n",
    "print(top_10_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Films:\n",
      "      Item ID                                        Movie Title\n",
      "44        423                  E.T. the Extra-Terrestrial (1982)\n",
      "277       875  Shes So Lovely (1997)|22-Aug-1997||http://us.i...\n",
      "543      1073                               Shallow Grave (1994)\n",
      "863      1012                               Private Parts (1997)\n",
      "932      1473                        Little Princess, The (1939)\n",
      "1542      594                                       Heavy (1995)\n",
      "2320     1643                                  Angel Baby (1995)\n",
      "2429      867                       Whole Wide World, The (1996)\n",
      "3594     1512             World of Apu, The (Apur Sansar) (1959)\n",
      "7906      868                            Hearts and Minds (1996)\n",
      "\n",
      "Watched Films:\n",
      "       Item ID                                        Movie Title\n",
      "1          159                              Basic Instinct (1992)\n",
      "3          184                            Army of Darkness (1993)\n",
      "5            4                                  Get Shorty (1995)\n",
      "8          238                             Raising Arizona (1987)\n",
      "10         218                                   Cape Fear (1991)\n",
      "...        ...                                                ...\n",
      "1435       244  Smillas Sense of Snow (1997)|14-Mar-1997||http...\n",
      "2322       253                            Pillow Book, The (1995)\n",
      "2448       224                                    Ridicule (1996)\n",
      "2871        16                 French Twist (Gazon maudit) (1995)\n",
      "12143      247                Turbo: A Power Rangers Movie (1997)\n",
      "\n",
      "[116 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the recommended films\n",
    "recommended_film_ids = top_10_recommendations['Item ID'].values\n",
    "recommended_films = global_train_df[global_train_df['Item ID'].isin(recommended_film_ids)][['Item ID', 'Movie Title']].drop_duplicates()\n",
    "\n",
    "# Get the names of the films the user has watched\n",
    "watched_film_ids = rated_items\n",
    "watched_films = global_train_df[global_train_df['Item ID'].isin(watched_film_ids)][['Item ID', 'Movie Title']].drop_duplicates()\n",
    "\n",
    "print(\"Recommended Films:\")\n",
    "print(recommended_films)\n",
    "\n",
    "print(\"\\nWatched Films:\")\n",
    "print(watched_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (2.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests->keras-tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\44747\\anaconda3\\envs\\groupassignment2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hyperparam_tuning\\tuner0.json\n",
      "\n",
      "The optimal embedding size is 50.\n",
      "The optimal number of dense units is 192.\n",
      "The optimal learning rate is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# Define a function to build the model\n",
    "def build_model(hp):\n",
    "    num_users = global_train_df['User ID'].max()\n",
    "    num_items = global_train_df['Item ID'].max()\n",
    "    \n",
    "    embedding_size = hp.Int('embedding_size', min_value=10, max_value=100, step=10)\n",
    "    dense_units = hp.Int('dense_units', min_value=32, max_value=256, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    item_input = Input(shape=(1,), name='item_input')\n",
    "    \n",
    "    user_embedding = Embedding(input_dim=num_users + 1, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "    item_embedding = Embedding(input_dim=num_items + 1, output_dim=embedding_size, name='item_embedding')(item_input)\n",
    "    \n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    \n",
    "    concat = Concatenate()([user_vecs, item_vecs])\n",
    "    \n",
    "    dense = Dense(dense_units, activation='relu')(concat)\n",
    "    output = Dense(1)(dense)\n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Prepare the training data\n",
    "X_train = [global_train_df['User ID'].values, global_train_df['Item ID'].values]\n",
    "y_train = global_train_df['Rating'].values\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The optimal embedding size is {best_hps.get('embedding_size')}.\n",
    "The optimal number of dense units is {best_hps.get('dense_units')}.\n",
    "The optimal learning rate is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">47,200</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">84,150</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,392</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m47,200\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m84,150\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │     \u001b[38;5;34m19,392\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m193\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,935</span> (589.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m150,935\u001b[0m (589.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,935</span> (589.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m150,935\u001b[0m (589.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "best_model = build_model(best_hps)\n",
    "\n",
    "# Print the summary of the model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0511 - val_loss: 1.5408\n",
      "Epoch 2/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0508 - val_loss: 1.5777\n",
      "Epoch 3/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0504 - val_loss: 1.5781\n",
      "Epoch 4/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0496 - val_loss: 1.5783\n",
      "Epoch 5/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0483 - val_loss: 1.5710\n",
      "Epoch 6/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0483 - val_loss: 1.5598\n",
      "Epoch 7/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0465 - val_loss: 1.5597\n",
      "Epoch 8/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0456 - val_loss: 1.5330\n",
      "Epoch 9/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0452 - val_loss: 1.5555\n",
      "Epoch 10/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0425 - val_loss: 1.6052\n",
      "Epoch 11/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0436 - val_loss: 1.6018\n",
      "Epoch 12/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0435 - val_loss: 1.5721\n",
      "Epoch 13/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0426 - val_loss: 1.5760\n",
      "Epoch 14/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0423 - val_loss: 1.5872\n",
      "Epoch 15/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0415 - val_loss: 1.5950\n",
      "Epoch 16/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0409 - val_loss: 1.5876\n",
      "Epoch 17/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0396 - val_loss: 1.5823\n",
      "Epoch 18/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0391 - val_loss: 1.5932\n",
      "Epoch 19/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0390 - val_loss: 1.5450\n",
      "Epoch 20/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0379 - val_loss: 1.5838\n",
      "Epoch 21/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - val_loss: 1.5876\n",
      "Epoch 22/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0371 - val_loss: 1.5697\n",
      "Epoch 23/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.0368 - val_loss: 1.5571\n",
      "Epoch 24/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0358 - val_loss: 1.5670\n",
      "Epoch 25/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0369 - val_loss: 1.5717\n",
      "Epoch 26/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0357 - val_loss: 1.5509\n",
      "Epoch 27/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - val_loss: 1.5750\n",
      "Epoch 28/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0346 - val_loss: 1.5485\n",
      "Epoch 29/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0344 - val_loss: 1.5635\n",
      "Epoch 30/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0338 - val_loss: 1.5458\n",
      "Epoch 31/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0341 - val_loss: 1.5682\n",
      "Epoch 32/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0328 - val_loss: 1.5597\n",
      "Epoch 33/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0328 - val_loss: 1.5586\n",
      "Epoch 34/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0322 - val_loss: 1.5472\n",
      "Epoch 35/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0315 - val_loss: 1.5580\n",
      "Epoch 36/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0325 - val_loss: 1.5689\n",
      "Epoch 37/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0323 - val_loss: 1.5471\n",
      "Epoch 38/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0314 - val_loss: 1.5472\n",
      "Epoch 39/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0313 - val_loss: 1.5418\n",
      "Epoch 40/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0297 - val_loss: 1.5511\n",
      "Epoch 41/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0285 - val_loss: 1.5505\n",
      "Epoch 42/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - val_loss: 1.5434\n",
      "Epoch 43/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0302 - val_loss: 1.5282\n",
      "Epoch 44/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0290 - val_loss: 1.5392\n",
      "Epoch 45/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - val_loss: 1.5185\n",
      "Epoch 46/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0286 - val_loss: 1.5415\n",
      "Epoch 47/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0278 - val_loss: 1.5711\n",
      "Epoch 48/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0279 - val_loss: 1.5262\n",
      "Epoch 49/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - val_loss: 1.5133\n",
      "Epoch 50/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.0271 - val_loss: 1.5190\n",
      "Epoch 51/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0280 - val_loss: 1.5418\n",
      "Epoch 52/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0261 - val_loss: 1.5132\n",
      "Epoch 53/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0274 - val_loss: 1.5289\n",
      "Epoch 54/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - val_loss: 1.5261\n",
      "Epoch 55/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0269 - val_loss: 1.5083\n",
      "Epoch 56/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0263 - val_loss: 1.5223\n",
      "Epoch 57/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0254 - val_loss: 1.4933\n",
      "Epoch 58/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - val_loss: 1.5161\n",
      "Epoch 59/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0262 - val_loss: 1.5049\n",
      "Epoch 60/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0256 - val_loss: 1.5242\n",
      "Epoch 61/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - val_loss: 1.5286\n",
      "Epoch 62/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0248 - val_loss: 1.5082\n",
      "Epoch 63/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0254 - val_loss: 1.5182\n",
      "Epoch 64/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0257 - val_loss: 1.5010\n",
      "Epoch 65/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - val_loss: 1.4941\n",
      "Epoch 66/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0250 - val_loss: 1.5136\n",
      "Epoch 67/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0239 - val_loss: 1.5136\n",
      "Epoch 68/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - val_loss: 1.4927\n",
      "Epoch 69/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - val_loss: 1.4976\n",
      "Epoch 70/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0236 - val_loss: 1.4997\n",
      "Epoch 71/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0240 - val_loss: 1.4852\n",
      "Epoch 72/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0241 - val_loss: 1.4917\n",
      "Epoch 73/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0241 - val_loss: 1.5045\n",
      "Epoch 74/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - val_loss: 1.5073\n",
      "Epoch 75/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 1.4896\n",
      "Epoch 76/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - val_loss: 1.4733\n",
      "Epoch 77/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0230 - val_loss: 1.4908\n",
      "Epoch 78/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - val_loss: 1.4699\n",
      "Epoch 79/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - val_loss: 1.4951\n",
      "Epoch 80/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0224 - val_loss: 1.4787\n",
      "Epoch 81/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0210 - val_loss: 1.4869\n",
      "Epoch 82/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - val_loss: 1.4885\n",
      "Epoch 83/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0223 - val_loss: 1.4771\n",
      "Epoch 84/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - val_loss: 1.4647\n",
      "Epoch 85/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - val_loss: 1.4870\n",
      "Epoch 86/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - val_loss: 1.4640\n",
      "Epoch 87/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0195 - val_loss: 1.4692\n",
      "Epoch 88/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0208 - val_loss: 1.4713\n",
      "Epoch 89/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0207 - val_loss: 1.4780\n",
      "Epoch 90/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0211 - val_loss: 1.4621\n",
      "Epoch 91/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0222 - val_loss: 1.4651\n",
      "Epoch 92/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 1.4620\n",
      "Epoch 93/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196 - val_loss: 1.4842\n",
      "Epoch 94/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - val_loss: 1.4736\n",
      "Epoch 95/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0200 - val_loss: 1.4745\n",
      "Epoch 96/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0209 - val_loss: 1.4720\n",
      "Epoch 97/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0219 - val_loss: 1.4552\n",
      "Epoch 98/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203 - val_loss: 1.4718\n",
      "Epoch 99/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - val_loss: 1.4630\n",
      "Epoch 100/100\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - val_loss: 1.4597\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step\n",
      "     Item ID  Predicted Rating\n",
      "359     1516          0.048999\n",
      "5        300          0.046037\n",
      "377     1576          0.045360\n",
      "329     1484          0.043168\n",
      "221     1302          0.042182\n",
      "270     1402          0.042118\n",
      "46       567          0.041953\n",
      "45       566          0.041694\n",
      "332     1487          0.041044\n",
      "13       426          0.040633\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict([user_input_pred, item_input_pred])\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame({'Item ID': unrated_items, 'Predicted Rating': predictions.flatten()})\n",
    "\n",
    "# Sort the predictions in descending order\n",
    "predictions_df = predictions_df.sort_values(by='Predicted Rating', ascending=False)\n",
    "\n",
    "# Get the top 10 recommendations\n",
    "top_10_recommendations = predictions_df.head(10)\n",
    "\n",
    "print(top_10_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Films:\n",
      "      Item ID                                        Movie Title\n",
      "17        566                    Clear and Present Danger (1994)\n",
      "76        300                               Air Force One (1997)\n",
      "321       426                Transformers: The Movie, The (1986)\n",
      "588       567  Wes Cravens New Nightmare (1994)|01-Jan-1994||...\n",
      "1021     1402                           Ciao, Professore! (1993)\n",
      "2360     1516                           Wedding Gift, The (1994)\n",
      "4768     1302                               Late Bloomers (1996)\n",
      "4825     1576                     Hungarian Fairy Tale, A (1987)\n",
      "4922     1484                             Jerky Boys, The (1994)\n",
      "4976     1487                 Even Cowgirls Get the Blues (1993)\n",
      "\n",
      "Watched Films:\n",
      "       Item ID                                        Movie Title\n",
      "1          159                              Basic Instinct (1992)\n",
      "3          184                            Army of Darkness (1993)\n",
      "5            4                                  Get Shorty (1995)\n",
      "8          238                             Raising Arizona (1987)\n",
      "10         218                                   Cape Fear (1991)\n",
      "...        ...                                                ...\n",
      "1435       244  Smillas Sense of Snow (1997)|14-Mar-1997||http...\n",
      "2322       253                            Pillow Book, The (1995)\n",
      "2448       224                                    Ridicule (1996)\n",
      "2871        16                 French Twist (Gazon maudit) (1995)\n",
      "12143      247                Turbo: A Power Rangers Movie (1997)\n",
      "\n",
      "[116 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the recommended films\n",
    "recommended_film_ids = top_10_recommendations['Item ID'].values\n",
    "recommended_films = global_train_df[global_train_df['Item ID'].isin(recommended_film_ids)][['Item ID', 'Movie Title']].drop_duplicates()\n",
    "\n",
    "# Get the names of the films the user has watched\n",
    "watched_film_ids = rated_items\n",
    "watched_films = global_train_df[global_train_df['Item ID'].isin(watched_film_ids)][['Item ID', 'Movie Title']].drop_duplicates()\n",
    "\n",
    "print(\"Recommended Films:\")\n",
    "print(recommended_films)\n",
    "\n",
    "print(\"\\nWatched Films:\")\n",
    "print(watched_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check if the recommeded films match any in our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches between recommended films and films watched by user 1 in the test set:\n",
      "Empty DataFrame\n",
      "Columns: [Item ID, Movie Title]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Get the films watched by user 1 in the test set\n",
    "user_test_watched_films = global_test_df[global_test_df['User ID'] == user_id][['Item ID', 'Movie Title']].drop_duplicates()\n",
    "\n",
    "# Check for matches between recommended films and watched films in the test set\n",
    "matches = recommended_films[recommended_films['Item ID'].isin(user_test_watched_films['Item ID'])]\n",
    "\n",
    "print(\"Matches between recommended films and films watched by user 1 in the test set:\")\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item ID</th>\n",
       "      <th>Movie Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>171</td>\n",
       "      <td>Delicatessen (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item ID          Movie Title\n",
       "5679        5       Copycat (1995)\n",
       "5680      171  Delicatessen (1991)\n",
       "5681      242         Kolya (1996)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test_watched_films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item ID  Rating          Movie Title\n",
      "0        5       3       Copycat (1995)\n",
      "1      171       5  Delicatessen (1991)\n",
      "2      242       5         Kolya (1996)\n"
     ]
    }
   ],
   "source": [
    "# Filter the global_test_df for the ratings given by user 1 to the films in user_test_watched_films\n",
    "user_1_ratings = global_test_df[(global_test_df['User ID'] == user_id) & (global_test_df['Item ID'].isin(user_test_watched_films['Item ID']))][['Item ID', 'Rating']]\n",
    "\n",
    "# Merge with user_test_watched_films to get the movie titles\n",
    "user_1_ratings_with_titles = user_1_ratings.merge(user_test_watched_films, on='Item ID')\n",
    "\n",
    "print(user_1_ratings_with_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distribution of ratings quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the distribution of movie ratings in the training set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(global_train_df['Rating'], bins=np.arange(0.5, 6, 0.5), edgecolor='black')\n",
    "plt.title('Distribution of Movie Ratings in Training Set')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GroupAssignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
